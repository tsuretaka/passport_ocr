import streamlit as st
import streamlit_authenticator as stauth
import yaml
from yaml.loader import SafeLoader
import os
import glob
from PIL import Image
from google.oauth2.service_account import Credentials
from google.cloud import vision
import io
import pillow_heif
import importlib
from datetime import datetime, timedelta
import pandas as pd

# Register HEIC opener
pillow_heif.register_heif_opener()

from pdf2image import convert_from_bytes

# Custom modules
import ocr_utils
importlib.reload(ocr_utils)
import excel_utils
importlib.reload(excel_utils)
importlib.reload(excel_utils)
import bcrypt
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, DataReturnMode, JsCode

# Page Config
st.set_page_config(page_title="ãƒ‘ã‚¹ãƒãƒ¼ãƒˆOCRã‚·ã‚¹ãƒ†ãƒ ", layout="wide")

def load_auth_config():
    # 1. Try Streamlit Secrets (for Cloud)
    # Streamlit Secrets handles TOML automatically and exposes it as a dict-like object
    # We expect the structure to match what Authenticator expects.
    if "credentials" in st.secrets:
        try:
            # Deep conversion to dict if necessary, or just return keys
            # Secrets might be locked, so we convert to a mutable dict for usage
            config = {
                'credentials': dict(st.secrets['credentials']),
                'cookie': dict(st.secrets['cookie']),
                'preauthorized': dict(st.secrets.get('preauthorized', {'emails': []}))
            }
            # Adjust nested 'usernames' dict inside credentials if it's AttrDict
            if 'usernames' in config['credentials']:
                config['credentials']['usernames'] = dict(config['credentials']['usernames'])
                for user, details in config['credentials']['usernames'].items():
                     config['credentials']['usernames'][user] = dict(details)
                     
            return config
        except Exception as e:
            st.error(f"Secretsã‹ã‚‰ã®è¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    # 2. Try Local File (for Local Dev)
    auth_file = "auth_config.yaml"
    if not os.path.exists(auth_file):
        st.error(f"{auth_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None
    with open(auth_file) as file:
        config = yaml.load(file, Loader=SafeLoader)
    return config

config = load_auth_config()

if config:
    authenticator = stauth.Authenticate(
        config['credentials'],
        config['cookie']['name'],
        config['cookie']['key'],
        config['cookie']['expiry_days']
    )

    authenticator.login(location='main')

    if st.session_state["authentication_status"] is False:
        st.error('ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™')
    elif st.session_state["authentication_status"] is None:
        st.warning('ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„')
    elif st.session_state["authentication_status"]:
        # --- LOGGED IN ---
        username = st.session_state["username"]
        name = st.session_state["name"]
        
        st.sidebar.write(f'Welcome *{name}*')
        authenticator.logout(location='sidebar')
        
        # --- ADMIN SECTION ---
        if username == 'admin':
            st.sidebar.markdown("---")
            with st.sidebar.expander("ğŸ‘¥ ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç† (Admin)", expanded=False):
                # 1. User List
                current_users = list(config['credentials']['usernames'].keys())
                st.write(f"ç™»éŒ²ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {len(current_users)}")
                st.code("\n".join(current_users))
                
                st.markdown("---")
                
                # 2. Add User
                st.subheader("ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ ")
                with st.form("add_user_form", clear_on_submit=True):
                    new_user = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼ID (è‹±æ•°å­—)")
                    new_name = st.text_input("è¡¨ç¤ºå")
                    new_pass = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
                    submitted = st.form_submit_button("è¿½åŠ ")
                    
                    if submitted:
                        if new_user and new_name and new_pass:
                            if new_user in config['credentials']['usernames']:
                                st.error("ãã®IDã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
                            else:
                                # Hash Password
                                hashed = bcrypt.hashpw(new_pass.encode(), bcrypt.gensalt()).decode()
                                
                                # Update Config Dict
                                config['credentials']['usernames'][new_user] = {
                                    'email': f"{new_user}@example.com", # Dummy or input
                                    'name': new_name,
                                    'password': hashed,
                                    'logged_in': False,
                                    'data_dir': f"./data/{new_user}"
                                }
                                
                                # Save to YAML
                                with open('auth_config.yaml', 'w') as f:
                                    yaml.dump(config, f, default_flow_style=False)
                                
                                st.success(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ '{new_user}' ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
                                st.rerun() # Refresh list
                        else:
                            st.error("å…¨é …ç›®ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

                st.markdown("---")
                
                # 3. Delete User
                st.subheader("ãƒ¦ãƒ¼ã‚¶ãƒ¼å‰Šé™¤")
                del_target = st.selectbox("å‰Šé™¤å¯¾è±¡", ["-"] + [u for u in current_users if u != 'admin'])
                if st.button("å‰Šé™¤å®Ÿè¡Œ"):
                    if del_target != "-":
                       del config['credentials']['usernames'][del_target]
                       # Save
                       with open('auth_config.yaml', 'w') as f:
                            yaml.dump(config, f, default_flow_style=False)
                       st.success(f"'{del_target}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                       st.rerun()

        # User Data Directory Setup
        if 'data_dir' in config['credentials']['usernames'][username]:
            user_data_dir = config['credentials']['usernames'][username]['data_dir']
        else:
            user_data_dir = f"./data/{username}"
            
        os.makedirs(user_data_dir, exist_ok=True)
        excel_path = os.path.join(user_data_dir, "passport_list.xlsx")
        
        st.title("ğŸ‡¯ğŸ‡µ ãƒ‘ã‚¹ãƒãƒ¼ãƒˆOCRè»¢è¨˜ã‚·ã‚¹ãƒ†ãƒ ")
        
        # --- GCP Credentials Setup ---
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®è¨­å®šã§ã¯ãªãã€ã‚·ã‚¹ãƒ†ãƒ å…±é€šã®ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½¿ã†
        # res_card_ocrã‹ã‚‰ã‚³ãƒ”ãƒ¼ã—ãŸ service_account.json ã‚’å‚ç…§
        # --- GCP Credentials Setup ---
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®è¨­å®šã§ã¯ãªãã€ã‚·ã‚¹ãƒ†ãƒ å…±é€šã®ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½¿ã†
        # ãƒ­ãƒ¼ã‚«ãƒ«ã§ã¯ service_account.json ã‚’å‚ç…§
        # ã‚¯ãƒ©ã‚¦ãƒ‰(Streamlit Cloudç­‰)ã§ã¯ st.secrets["gcp_service_account"] ã‚’å‚ç…§
        SERVICE_ACCOUNT_FILE = "service_account.json"
        
        def get_vision_client():
            # 1. Try Local File
            if os.path.exists(SERVICE_ACCOUNT_FILE):
                creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE)
                return vision.ImageAnnotatorClient(credentials=creds)
            
            # 2. Try Streamlit Secrets
            elif "gcp_service_account" in st.secrets:
                try:
                    # st.secrets returns a AttrDict, transform to normal dict for from_service_account_info
                    info = dict(st.secrets["gcp_service_account"])
                    creds = Credentials.from_service_account_info(info)
                    return vision.ImageAnnotatorClient(credentials=creds)
                except Exception as e:
                     st.error(f"Secretsã‹ã‚‰ã®èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                     return None
            else:
                st.error("GCPèªè¨¼æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚(service_account.json ã¾ãŸã¯ st.secrets)")
                return None

        vision_client = get_vision_client()
        
        # --- Tabs ---
        tab1, tab2, tab3 = st.tabs(["ğŸ“· å˜ç¥¨èª­ã¿å–ã‚Š", "ğŸ“‚ ä¸€æ‹¬èª­ã¿å–ã‚Š (ãƒ•ã‚©ãƒ«ãƒ€æŒ‡å®š)", "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç®¡ç†"])
        
        # ==========================================
        # TAB 1: Single Scan
        # ==========================================
        with tab1:
            st.header("1æšãšã¤èª­ã¿å–ã‚Šãƒ»ç™»éŒ²")
            
            uploaded_file = st.file_uploader("ãƒ‘ã‚¹ãƒãƒ¼ãƒˆç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['png', 'jpg', 'jpeg', 'heic', 'pdf'], key='single_uploader')
            
            if uploaded_file:
                # Handle HEIC or standard image or PDF
                try:
                    if uploaded_file.name.lower().endswith('.heic'):
                        image = Image.open(uploaded_file)
                    elif uploaded_file.name.lower().endswith('.pdf'):
                        # Convert PDF first page to image
                        pages = convert_from_bytes(uploaded_file.read())
                        if pages:
                            image = pages[0]
                        else:
                            st.error("PDFãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                            image = None
                    else:
                        image = Image.open(uploaded_file)
                        
                    if image:
                        st.image(image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ", use_container_width=True)
                except Exception as e:
                    st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ: {e}")
                    image = None
                
                # Options - Removed FAX mode as per request
                # use_fax_mode = st.checkbox("ä½ç”»è³ªãƒ»FAXãƒ¢ãƒ¼ãƒ‰...", ...)

                if image and st.button("OCRè§£æé–‹å§‹", key='btn_single_ocr'):
                    if not vision_client:
                        st.error("OCRã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    else:
                        with st.spinner("è§£æä¸­..."):
                            img_byte_arr = io.BytesIO()
                            image.save(img_byte_arr, format='JPEG') # Convert to JPEG for Vision API
                            content = img_byte_arr.getvalue()
                            
                            vision_image = vision.Image(content=content)
                            response = vision_client.text_detection(image=vision_image)
                            
                            if response.error.message:
                                st.error(f"Error: {response.error.message}")
                            else:

                                passport_data = ocr_utils.parse_response(response)
                                
                                # FORCE NORMALIZE LOCALLY (Aggressive Whitelist)
                                import unicodedata
                                import re
                                def aggressive_normalize(val, allow_slash=False):
                                    if not val: return val
                                    s = str(val)
                                    # 1. NFKC (Full-width -> Half-width)
                                    s = unicodedata.normalize('NFKC', s)
                                    s = s.upper()
                                    # 2. Whitelist filtering
                                    if allow_slash:
                                        # For dates: Allow A-Z, 0-9, and /
                                        s = re.sub(r'[^A-Z0-9/]', '', s)
                                    else:
                                        # For names/IDs: Allow A-Z, 0-9 ONLY. Kills all spaces/symbols.
                                        s = re.sub(r'[^A-Z0-9]', '', s)
                                    return s
                                
                                # Apply to specific keys
                                for k in ['passport_no', 'surname', 'given_name', 'sex', 'nationality', 'domicile']:
                                    passport_data[k] = aggressive_normalize(passport_data.get(k), allow_slash=False)
                                
                                for k in ['birth_date', 'issue_date', 'expiry_date']:
                                    passport_data[k] = aggressive_normalize(passport_data.get(k), allow_slash=True)
                                
                                st.session_state['current_mrz_data'] = passport_data
                                st.success("è§£æå®Œäº†")
                                
                                with st.expander("è§£æè©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"):
                                    st.write("è§£æçµæœ:", passport_data)
                                    if response.text_annotations:
                                        st.write("ç”Ÿãƒ†ã‚­ã‚¹ãƒˆ:", response.text_annotations[0].description)

                if 'current_mrz_data' in st.session_state:
                    data = st.session_state['current_mrz_data']
                    
                    st.markdown("### è§£æçµæœç¢ºèª")
                    
                    # Top Row
                    r1c1, r1c2, r1c3 = st.columns(3)
                    with r1c1:
                        st.text("æ—…åˆ¸ç•ªå·")
                        st.info(data.get('passport_no', ''))
                    with r1c2:
                        st.text("ç”Ÿå¹´æœˆæ—¥")
                        st.info(data.get('birth_date', ''))
                    with r1c3:
                        st.text("æ€§åˆ¥")
                        st.info(data.get('sex', ''))

                    # Name Row
                    r2c1, r2c2 = st.columns(2)
                    with r2c1:
                        st.text("æ°å (å§“)")
                        st.info(data.get('surname', ''))
                    with r2c2:
                        st.text("æ°å (å)")
                        st.info(data.get('given_name', ''))

                    # Domicile / Nationality Row (New)
                    r3c1, r3c2 = st.columns(2)
                    with r3c1:
                        st.text("æœ¬ç± (Registered Domicile)")
                        st.info(data.get('domicile', ''))
                    with r3c2:
                        st.text("å›½ç±")
                        st.info(data.get('nationality', ''))

                    # Dates Row (New)
                    r4c1, r4c2 = st.columns(2)
                    with r4c1:
                        st.text("ç™ºè¡Œå¹´æœˆæ—¥")
                        st.info(data.get('issue_date', ''))
                    with r4c2:
                        st.text("æœ‰åŠ¹æœŸé–“æº€äº†æ—¥")
                        st.info(data.get('expiry_date', ''))
                    
                    # Input Row
                    r5c1, r5c2 = st.columns(2)
                    with r5c1:
                        st.text("ä½æ‰€ (æ‰‹å…¥åŠ›)")
                        data['address'] = st.text_input("address_input", value=data.get('address', ''), label_visibility="collapsed")
                    with r5c2:
                        st.text("å‚™è€ƒ")
                        data['note'] = st.text_area("note_input", value=data.get('note', ''), height=38, label_visibility="collapsed")
                    
                    if st.button("ç™»éŒ²ã™ã‚‹", type="primary"):
                        # excel_utils.save_passport_data(excel_path, data, image_filename=uploaded_file.name)
                        
                        # Append to Session State 'manage_df'
                        if 'manage_df' not in st.session_state:
                             # Initialize if managing first time
                             st.session_state['manage_df'] = pd.DataFrame() # Load empty or init structure
                             # Actually we should ideally load existing if any, but we are moving away from file persistence.
                             # If we want to support mixed mode, we'd load here. 
                             # For now, let's assume fresh start or respect existing session.
                             
                        # Create row
                        new_row = {
                            "ç™»éŒ²æ—¥æ™‚": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "æ—…åˆ¸ç•ªå·": data.get("passport_no", ""),
                            "æ°å(å§“)": data.get("surname", ""),
                            "æ°å(å)": data.get("given_name", ""),
                            "ç”Ÿå¹´æœˆæ—¥": data.get("birth_date", ""),
                            "æ€§åˆ¥": data.get("sex", ""),
                            "å›½ç±": data.get("nationality", ""),
                            "æœ¬ç±": data.get("domicile", ""),
                            "ç™ºè¡Œå¹´æœˆæ—¥": data.get("issue_date", ""),
                            "æœ‰åŠ¹æœŸé–“æº€äº†æ—¥": data.get("expiry_date", ""),
                            "ä½æ‰€(æ‰‹å…¥åŠ›)": data.get("address", ""),
                            "å‚™è€ƒ": data.get("note", ""),
                            "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å": uploaded_file.name
                        }
                        
                        current_df = st.session_state.get('manage_df', pd.DataFrame())
                        new_df = pd.DataFrame([new_row])
                        st.session_state['manage_df'] = pd.concat([current_df, new_df], ignore_index=True)

                        st.success("ãƒªã‚¹ãƒˆã«è¿½åŠ ã—ã¾ã—ãŸï¼ï¼ˆâ€»ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã¯ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¿ãƒ–ã‹ã‚‰è¡Œã£ã¦ãã ã•ã„ï¼‰")
                        st.session_state.pop('current_mrz_data', None)
                             
                        st.rerun()
                            
        # ==========================================
        # TAB 2: Batch Scan
        # ==========================================
        # ==========================================
        # TAB 2: Batch Scan (Upload)
        # ==========================================
        with tab2:
            st.header("è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ä¸€æ‹¬èª­ã¿å–ã‚Š")
            st.info("è¤‡æ•°ã®ãƒ‘ã‚¹ãƒãƒ¼ãƒˆç”»åƒã‚’ã¾ã¨ã‚ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ä¸€æ°—ã«ãƒªã‚¹ãƒˆã¸è¿½åŠ ã—ã¾ã™ã€‚")
            
            uploaded_files = st.file_uploader("ç”»åƒã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ— (è¤‡æ•°å¯)", type=['png', 'jpg', 'jpeg', 'heic', 'pdf'], accept_multiple_files=True, key='batch_uploader')
            
            # Batch Settings - Removed FAX mode
            # st.markdown("##### è¨­å®š")
            # batch_fax_mode = st.checkbox(...)

            if uploaded_files:
                st.write(f"é¸æŠæ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«: {len(uploaded_files)} ä»¶")
                
                if st.button("ä¸€æ‹¬è§£æé–‹å§‹", key='btn_batch_ocr'):
                    if not vision_client: st.error("OCR Engine Error")
                    else:
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        count = 0
                        
                        # Use session DF or create if not exists
                        current_df = st.session_state.get('manage_df', pd.DataFrame())
                        
                        # Prepare list for new rows
                        new_rows = []

                        for i, file in enumerate(uploaded_files):
                            status_text.text(f"å‡¦ç†ä¸­ ({i+1}/{len(uploaded_files)}): {file.name}")
                            try:
                                # Open Image from memory
                                if file.name.lower().endswith('.heic'):
                                    image = Image.open(file)
                                elif file.name.lower().endswith('.pdf'):
                                    # For batch, we only take the 1st page of PDF for now (Standard passport PDF scan)
                                    # If user needs multi-page OCR from one PDF, logic needs to be loop based.
                                    # Assuming 1 PDF = 1 Page Passport
                                    pages = convert_from_bytes(file.read())
                                    if pages: image = pages[0]
                                    else: 
                                        st.error(f"{file.name}: PDF page empty")
                                        continue
                                else:
                                    image = Image.open(file)

                                # Vision API
                                img_byte_arr = io.BytesIO()
                                image.save(img_byte_arr, format='JPEG')
                                content = img_byte_arr.getvalue()
                                vision_image = vision.Image(content=content)
                                response = vision_client.text_detection(image=vision_image)
                                
                                # Parse
                                p_data = ocr_utils.parse_response(response)
                                
                                # FORCE NORMALIZE LOCALLY (Aggressive Whitelist)
                                import unicodedata
                                import re
                                def aggressive_normalize(val, allow_slash=False):
                                    if not val: return val
                                    s = str(val)
                                    s = unicodedata.normalize('NFKC', s)
                                    s = s.upper()
                                    if allow_slash:
                                        s = re.sub(r'[^A-Z0-9/]', '', s)
                                    else:
                                        s = re.sub(r'[^A-Z0-9]', '', s)
                                    return s

                                for k in ['passport_no', 'surname', 'given_name', 'sex', 'nationality', 'domicile']:
                                    p_data[k] = aggressive_normalize(p_data.get(k), allow_slash=False)
                                
                                for k in ['birth_date', 'issue_date', 'expiry_date']:
                                    p_data[k] = aggressive_normalize(p_data.get(k), allow_slash=True)
                                
                                # Create Row Data
                                row = {
                                    "ç™»éŒ²æ—¥æ™‚": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                    "æ—…åˆ¸ç•ªå·": p_data.get("passport_no", ""),
                                    "æ°å(å§“)": p_data.get("surname", ""),
                                    "æ°å(å)": p_data.get("given_name", ""),
                                    "ç”Ÿå¹´æœˆæ—¥": p_data.get("birth_date", ""),
                                    "æ€§åˆ¥": p_data.get("sex", ""),
                                    "å›½ç±": p_data.get("nationality", ""),
                                    "æœ¬ç±": p_data.get("domicile", ""),
                                    "ç™ºè¡Œå¹´æœˆæ—¥": p_data.get("issue_date", ""),
                                    "æœ‰åŠ¹æœŸé–“æº€äº†æ—¥": p_data.get("expiry_date", ""),
                                    "ä½æ‰€(æ‰‹å…¥åŠ›)": p_data.get("address", ""),
                                    "å‚™è€ƒ": p_data.get("note", ""),
                                    "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å": file.name
                                }
                                new_rows.append(row)
                                count += 1
                                
                            except Exception as e:
                                st.error(f"Error {file.name}: {e}")
                            
                            progress_bar.progress((i + 1) / len(uploaded_files))
                        
                        if new_rows:
                            new_df = pd.DataFrame(new_rows)
                            # Append to manage_df in session (Memory Only)
                            # If manage_df is loaded from excel initially, we append to it.
                            # But since we want to STOP using excel file as storage, we effectively treat manage_df as the master.
                            if 'manage_df' not in st.session_state:
                                st.session_state['manage_df'] = excel_utils.load_data_as_df(excel_path)
                            
                            st.session_state['manage_df'] = pd.concat([st.session_state['manage_df'], new_df], ignore_index=True)

                        status_text.text("å®Œäº†")
                        st.success(f"{count} ä»¶ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ ã—ã¾ã—ãŸã€‚ã€Œãƒ‡ãƒ¼ã‚¿ç®¡ç†ã€ã‚¿ãƒ–ã§ç¢ºèªãƒ»ä¿å­˜ã—ã¦ãã ã•ã„ã€‚")

        # ==========================================
        # TAB 3: Data Management
        # ==========================================
        # ==========================================
        # TAB 3: Data Management
        # ==========================================
        with tab3:
            st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã¯ä¸€æ™‚ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚¯ãƒ©ã‚¦ãƒ‰ä¸Šã«ã¯ä¿å­˜ã•ã‚Œã¾ã›ã‚“ã€‚å¿…ãšæœ€å¾Œã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

            # Initialize session data
            if 'manage_df' not in st.session_state:
                st.session_state['manage_df'] = pd.DataFrame(columns=[
                "ç™»éŒ²æ—¥æ™‚", "æ—…åˆ¸ç•ªå·", "æ°å(å§“)", "æ°å(å)", 
                "ç”Ÿå¹´æœˆæ—¥", "æ€§åˆ¥", "å›½ç±", "æœ¬ç±", "ç™ºè¡Œå¹´æœˆæ—¥", "æœ‰åŠ¹æœŸé–“æº€äº†æ—¥", 
                "ä½æ‰€(æ‰‹å…¥åŠ›)", "å‚™è€ƒ", "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"
            ])
            
            # --- 1. Passport Validity Check Section ---
            st.markdown("### ğŸ›‚ æ¸¡èˆªè¦ä»¶ãƒã‚§ãƒƒã‚¯ (æ®‹å­˜æœ‰åŠ¹æœŸé–“)")
            with st.expander("ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã‚’é–‹ã", expanded=True):
                ck1, ck2, ck3 = st.columns([2, 2, 2])
                with ck1:
                    entry_date = st.date_input("å…¥å›½äºˆå®šæ—¥", help="æ¸¡èˆªå…ˆã®å›½ã«å…¥å›½ã™ã‚‹æ—¥ä»˜")
                with ck2:
                    required_days = st.number_input("å¿…è¦ãªæ®‹å­˜æ—¥æ•°", min_value=0, value=180, step=30, help="ä¾‹: 6ãƒ¶æœˆãªã‚‰ç´„180æ—¥")
                with ck3:
                    st.write("") # Spacer
                    check_clicked = st.button("âœ… ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ", type="primary")
            
            # --- Perform Check Logic ---
            df_current = st.session_state['manage_df']
            
            if check_clicked and not df_current.empty:
                # Create a copy for analysis
                check_df = df_current.copy()
                
                def validate_expiry(expiry_str):
                    if not expiry_str or pd.isna(expiry_str):
                        return "ä¸æ˜ (ç©ºæ¬„)"
                    try:
                        exp_dt = datetime.strptime(str(expiry_str).strip(), "%Y/%m/%d").date()
                        limit_date = entry_date + timedelta(days=required_days)
                        if exp_dt >= limit_date: return "OK"
                        else: return "NG (æœŸé™åˆ‡ã‚Œ/æ®‹å­˜ä¸è¶³)"
                    except: return "ä¸æ˜ (å½¢å¼ã‚¨ãƒ©ãƒ¼)"

                check_df["åˆ¤å®šçµæœ"] = check_df["æœ‰åŠ¹æœŸé–“æº€äº†æ—¥"].apply(validate_expiry)
                
                ng_items = check_df[check_df["åˆ¤å®šçµæœ"].str.contains("NG", na=False)]
                
                if not ng_items.empty:
                    st.error(f"âš ï¸ {len(ng_items)} ä»¶ãŒè¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ï¼")
                    st.dataframe(ng_items[["æ—…åˆ¸ç•ªå·", "æ°å(å§“)", "æœ‰åŠ¹æœŸé–“æº€äº†æ—¥", "åˆ¤å®šçµæœ"]])
                else:
                    st.success("ğŸ‰ å…¨å“¡OKã§ã™ï¼")

            # --- 2. Data Cleaning Section (New) ---
            st.markdown("### ğŸ§¹ ãƒ‡ãƒ¼ã‚¿è£œæ­£")
            with st.expander("ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ï¼ˆæœ¬ç±ã®ä¿®æ­£ã€å…¨è§’â†’åŠè§’å¤‰æ›ãªã©ï¼‰", expanded=False):
                st.info("ã€Œæœ¬ç±ã€ã®ãƒã‚¤ã‚ºé™¤å»ã«åŠ ãˆã€å…¨è§’è‹±æ•°å­—ï¼ˆä¾‹ï¼šï¼«ï¼¡ï¼®ï¼¡ï¼´ï¼¡ï¼‰ã‚’åŠè§’ï¼ˆKANATAï¼‰ã«çµ±ä¸€ã—ã¾ã™ã€‚")
                if st.button("âœ¨ ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬è£œæ­£ãƒ»æ­£è¦åŒ–ã™ã‚‹"):
                    if not st.session_state['manage_df'].empty:
                        df_clean = st.session_state['manage_df'].copy()
                        
                        count_fixed = 0
                        
                        # Apply Cleaning using the same logic as ocr_utils
                        # Use direct module access ensuring we get the latest
                        import ocr_utils
                        
                        # Ensure we use a fresh normalization logic locally
                        import unicodedata
                        import re

                        def aggressive_normalize(val, allow_slash=False):
                            if not val or pd.isna(val): return val
                            s = str(val)
                            s = unicodedata.normalize('NFKC', s)
                            s = s.upper()
                            if allow_slash:
                                s = re.sub(r'[^A-Z0-9/]', '', s)
                            else:
                                s = re.sub(r'[^A-Z0-9]', '', s)
                            return s

                        def clean_domicile(val):
                            if not val or pd.isna(val): return val
                            # Normalize
                            val = aggressive_normalize(val, allow_slash=False)
                            # Check Prefectures
                            if hasattr(ocr_utils, 'JAPAN_PREFECTURES'):
                                for pref in ocr_utils.JAPAN_PREFECTURES:
                                    if pref in val:
                                        return pref
                            return val
                        
                        # Check diff
                        for index, row in df_clean.iterrows():
                            # Fix Domicile
                            orig_dom = row['æœ¬ç±']
                            cleaned_dom = clean_domicile(orig_dom)
                            
                            row_changed = False
                            
                            if orig_dom != cleaned_dom:
                                df_clean.at[index, 'æœ¬ç±'] = cleaned_dom
                                row_changed = True
                            
                            # Fix other columns with aggressive whitelist
                            # No slash allowed:
                            for col in ["æ—…åˆ¸ç•ªå·", "æ°å(å§“)", "æ°å(å)", "æ€§åˆ¥", "å›½ç±"]:
                                if col in row:
                                    orig = row[col]
                                    new_val = aggressive_normalize(orig, allow_slash=False)
                                    if orig != new_val:
                                        df_clean.at[index, col] = new_val
                                        row_changed = True
                            
                            # Slash allowed (Dates):
                            for col in ["ç”Ÿå¹´æœˆæ—¥", "ç™ºè¡Œå¹´æœˆæ—¥", "æœ‰åŠ¹æœŸé–“æº€äº†æ—¥"]:
                                if col in row:
                                    orig = row[col]
                                    new_val = aggressive_normalize(orig, allow_slash=True)
                                    if orig != new_val:
                                        df_clean.at[index, col] = new_val
                                        row_changed = True
                            
                            if row_changed:
                                count_fixed += 1
                        
                        st.session_state['manage_df'] = df_clean
                        
                        # IMPORTANT: Clear data_editor state to force refresh
                        if "data_editor_mem" in st.session_state:
                            del st.session_state["data_editor_mem"]
                            
                        if count_fixed > 0:
                            st.success(f"{count_fixed} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¼·åŠ›è£œæ­£ã—ã¾ã—ãŸï¼ˆè‹±æ•°å­—ä»¥å¤–ã‚’å‰Šé™¤ï¼‰ï¼")
                            st.rerun()
                        else:
                            st.info("è£œæ­£ãŒå¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆã™ã¹ã¦æ­£å¸¸ã‹ã€ãƒãƒƒãƒã—ã¾ã›ã‚“ã§ã—ãŸï¼‰ã€‚")
                    else:
                        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚")

            st.markdown("---")

            # --- 3. Data Editor Section ---
            df_current = st.session_state['manage_df']
            
            if not df_current.empty:
                # AgGrid Implementation for Drag & Drop
                from st_aggrid import AgGrid, GridOptionsBuilder

                gb = GridOptionsBuilder.from_dataframe(df_current)
                # Enable selection
                gb.configure_selection('multiple', use_checkbox=True, groupSelectsChildren=True)
                # Enable editing
                gb.configure_default_column(editable=True, groupable=True)
                # Enable Row Dragging on the first column (or specific column)
                # We add drag handle to 'æ—…åˆ¸ç•ªå·' or create an index col
                # Let's add drag handle to "æ—…åˆ¸ç•ªå·"
                gb.configure_column("æ—…åˆ¸ç•ªå·", rowDrag=True)
                
                # Dynamic height based on rows
                grid_height = 400
                if len(df_current) > 10: grid_height = 600
                
                gb.configure_grid_options(rowDragManaged=True, animateRows=True)
                gridOptions = gb.build()

                st.warning("âš ï¸ é‡è¦: è¡Œã‚’ãƒ‰ãƒ©ãƒƒã‚°ã—ã¦ä¸¦ã³æ›¿ãˆãŸå¾Œã¯ã€**å¿…ãšä»»æ„ã®è¡Œã‚’1å›ã‚¯ãƒªãƒƒã‚¯ï¼ˆã¾ãŸã¯ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’ON/OFFï¼‰** ã—ã¦ãã ã•ã„ã€‚\nã“ã‚Œã‚’è¡Œã‚ãªã„ã¨ã€æ–°ã—ã„ä¸¦ã³é †ãŒã‚·ã‚¹ãƒ†ãƒ ã«èªè­˜ã•ã‚Œã¾ã›ã‚“ï¼ˆä»•æ§˜ä¸Šã®åˆ¶é™ã§ã™ï¼‰ã€‚\nä¸‹ã®ã€Œç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ èªè­˜é †åºã€ãŒå¤‰ã‚ã£ãŸã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰ä¿å­˜ã—ã¦ãã ã•ã„ã€‚")

                # Ensure we capture ANY change including row movement if possible (Row Dragging is tricky in Streamlit-AgGrid)
                # But 'MODEL_CHANGED' should cover it. We will try to monitor selection too just in case.
                
                grid_response = AgGrid(
                    df_current,
                    gridOptions=gridOptions,
                    height=grid_height, 
                    width='100%',
                    data_return_mode=DataReturnMode.FILTERED_AND_SORTED, 
                    update_mode=GridUpdateMode.MODEL_CHANGED | GridUpdateMode.VALUE_CHANGED | GridUpdateMode.SELECTION_CHANGED,
                    fit_columns_on_grid_load=False,
                    allow_unsafe_jscode=True, 
                    key='passport_grid' 
                )

                selected = grid_response['selected_rows']
                updated_df_from_grid = grid_response['data'] # This should be a DataFrame or List of Dicts

                # Debug: Show top 3 names from the GRID response (not session state yet)
                # This helps user confirm if the drag was recognized by Python
                if isinstance(updated_df_from_grid, pd.DataFrame) and not updated_df_from_grid.empty:
                    top_names_preview = [f"{r.get('æ°å(å§“)','')} {r.get('æ°å(å)','')}" for i, r in updated_df_from_grid.head(3).iterrows()]
                elif isinstance(updated_df_from_grid, list) and updated_df_from_grid:
                     top_names_preview = [f"{r.get('æ°å(å§“)','')} {r.get('æ°å(å)','')}" for r in updated_df_from_grid[:3]]
                else:
                    top_names_preview = []

                # Convert List to DF if needed
                if not isinstance(updated_df_from_grid, pd.DataFrame):
                    updated_df_from_grid = pd.DataFrame(updated_df_from_grid)

                # Automatic Sync Logic (No manual Save button needed)
                # If the data returned from AgGrid is different from the current session state, update immediately.
                
                # Check if we have valid data back
                if not updated_df_from_grid.empty:
                    # To compare, we need to be careful about types and index.
                    # Let's perform a lightweight check: if the list of passport numbers in order is different.
                    
                    current_passport_order = df_current['æ—…åˆ¸ç•ªå·'].tolist() if 'æ—…åˆ¸ç•ªå·' in df_current.columns else []
                    new_passport_order = updated_df_from_grid['æ—…åˆ¸ç•ªå·'].tolist() if 'æ—…åˆ¸ç•ªå·' in updated_df_from_grid.columns else []
                    
                    # Also check content changes (for edits)
                    # Simple approach: If user interacted (which triggered this rerun), trust the grid data.
                    # But we need to distinguish between "Initial Load" and "User Change".
                    # updated_df_from_grid is initially same as df_current.
                    
                    # We can assume if selected_rows changed or if we detect value diffs.
                    # But easiest is: If the serialized data differs, update.
                    
                    # Clean up Grid data for comparison/saving
                    clean_new_df = updated_df_from_grid.copy()
                    if "_selectedRowNodeInfo" in clean_new_df.columns:
                        clean_new_df = clean_new_df.drop(columns=["_selectedRowNodeInfo"])
                    clean_new_df = clean_new_df.reset_index(drop=True)

                    # Compare with current state (df_current) - reset index for comparison too
                    df_current_reset = df_current.reset_index(drop=True)
                    
                    # Check if actually changed. We use .equals() but it can be strict.
                    # Let's check 2 things: Order of Passport No, and Values.
                    
                    has_changed = False
                    
                    # 1. Order Check
                    if current_passport_order != new_passport_order:
                        has_changed = True
                    
                    # 2. Content Check (if order is same, maybe values changed)
                    if not has_changed:
                        try:
                            # Drop compare artifacts
                            c1 = df_current_reset.drop(columns=['å‰Šé™¤å¯¾è±¡'], errors='ignore')
                            c2 = clean_new_df.drop(columns=['å‰Šé™¤å¯¾è±¡'], errors='ignore')
                            
                            # Align columns safely using intersection
                            common_cols = [c for c in c1.columns if c in c2.columns]
                            
                            # If columns differ significantly, we should probably update
                            if len(common_cols) != len(c1.columns) or len(common_cols) != len(c2.columns):
                                has_changed = True
                            else:
                                # Compare content of common columns
                                if not c1[common_cols].equals(c2[common_cols]):
                                    has_changed = True
                        except Exception as e:
                            # If comparison fails, assume changed to be safe and avoid crash
                            # st.error(f"Debug: Compare error {e}")
                            has_changed = True

                    if has_changed:
                        st.session_state['manage_df'] = clean_new_df
                        st.toast("âœ… ãƒ‡ãƒ¼ã‚¿ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸï¼ˆä¸¦ã³æ›¿ãˆãƒ»ç·¨é›†ï¼‰")
                        # Force Rerun to update the Grid with new clean data and prevent regression
                        st.rerun()

                col_btn1, col_btn2 = st.columns(2)
                
                with col_btn1:
                    if st.button("ğŸ—‘ï¸ é¸æŠè¡Œã‚’å‰Šé™¤"):
                         # Remove from memory
                        if selected:
                             # ... (Delete logic)
                             pass 
                        # (Reuse existing delete logic below, simplified)
                        
                        if selected:
                            try:
                                # Convert to list of dicts logic again
                                current_records = clean_new_df.to_dict('records') # Use clean_new_df (latest)
                                clean_selected = [{k:v for k,v in s.items() if k != '_selectedRowNodeInfo'} for s in selected]
                                
                                # Filter
                                # We need a reliable way to remove. 
                                # Since we have updated session state, we can just remove from valid list.
                                # But we need to identify WHICH rows.
                                
                                # Let's use index if possible, but index changes.
                                # Using Passport No + Name as pseudo key?
                                # Let's try removing exact matches from records.
                                
                                final_records = []
                                for r in current_records:
                                    is_selected = False
                                    for s in clean_selected:
                                        # Compare key fields
                                        if r.get('æ—…åˆ¸ç•ªå·') == s.get('æ—…åˆ¸ç•ªå·') and r.get('æ°å(å§“)') == s.get('æ°å(å§“)'):
                                            is_selected = True
                                            break
                                    if not is_selected:
                                        final_records.append(r)
                                
                                st.session_state['manage_df'] = pd.DataFrame(final_records)
                                st.success(f"{len(clean_selected)} ä»¶å‰Šé™¤ã—ã¾ã—ãŸ")
                                st.rerun()
                                
                            except Exception as e:
                                st.error(f"å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
                        else:
                            st.warning("å‰Šé™¤ã™ã‚‹è¡Œã‚’é¸æŠã—ã¦ãã ã•ã„")

                # Show current order preview
                st.caption(f"ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿é †åº: {', '.join(top_names_preview)} ...")

                st.markdown("### ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›")
                # Excel Download
                buffer = io.BytesIO()
                dl_df = st.session_state['manage_df'].copy()
                
                # Cleanup for download
                if "å‰Šé™¤å¯¾è±¡" in dl_df.columns:
                    dl_df = dl_df.drop(columns=["å‰Šé™¤å¯¾è±¡"])
                # Also removing internal aggrid cols just in case
                if "_selectedRowNodeInfo" in dl_df.columns:
                    dl_df = dl_df.drop(columns=["_selectedRowNodeInfo"])

                with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                    dl_df.to_excel(writer, index=False, sheet_name='Passport Data')
                
                st.download_button(
                    label="ğŸ“¥ Excelãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=buffer.getvalue(),
                    file_name=f"passport_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    type="primary",
                    key=f"dl_btn_{len(dl_df)}_{datetime.now().strftime('%S')}" # Unique key to force re-render
                )

            else:
                st.info("ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

